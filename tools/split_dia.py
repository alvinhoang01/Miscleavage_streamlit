import os
import re
import pandas as pd
import gc  # ‚úÖ Import garbage collector for memory management

def split_dia(param):
    """
    Function to split DIA search results into separate sample files.
    :param param: Dictionary of parameters loaded from YAML.
    :return: List of logs/messages for Streamlit UI.
    """

    logs = []  # ‚úÖ Store messages for UI
    path = param['input_file']

    # ‚úÖ Check if input file exists
    if not os.path.exists(path):
        error_msg = f"‚ùå Error: Input file not found at {path}"
        logs.append(error_msg)
        print(error_msg)
        return logs

    # ‚úÖ Ensure output directory exists
    output_dir = os.path.join(param['output_dir'], "step1-split")
    os.makedirs(output_dir, exist_ok=True)
    logs.append(f"üìÇ Output directory created: {output_dir}")

    # ‚úÖ Read DIA results in chunks (prevents full RAM usage)
    try:
        data_iter = pd.read_csv(path, sep="\t", chunksize=50000)  # ‚úÖ Process in smaller batches
    except Exception as e:
        error_msg = f"‚ùå Error reading input file: {e}"
        logs.append(error_msg)
        print(error_msg)
        return logs

    # ‚úÖ Extract and Split Data
    headers = ["PG.ProteinNames", "PEP.StrippedSequence"]
    num_files = 0

    for chunk in data_iter:  # ‚úÖ Process in chunks
        columns = chunk.columns.values
        samples = [i for i in columns if re.search(r".PEP.Quantity", i)]

        if not samples:
            warning_msg = "‚ö† No valid sample columns found! Check input file format."
            logs.append(warning_msg)
            print(warning_msg)
            return logs

        for sample in samples:
            try:
                df = chunk.loc[:, headers + [sample]]
                base_name = sample.split(".")[0].split(" ")[1]
                output_path = os.path.join(output_dir, f"{base_name}.split.tsv")

                df.to_csv(output_path, index=False, sep="\t")

                # ‚úÖ Reduce logging output to avoid memory issues
                if num_files % 10 == 0:  # ‚úÖ Print only for every 10th file
                    print(f"‚úî {sample} was saved to {output_path}")
                
                logs.append(f"‚úî {sample} was saved to {output_path}")
                num_files += 1

                del df  # ‚úÖ Free memory after writing
                gc.collect()  # ‚úÖ Force Python to free memory

            except Exception as e:
                error_msg = f"‚ùå Error processing {sample}: {e}"
                logs.append(error_msg)
                print(error_msg)

    if num_files == 0:
        logs.append("‚ö† No split files were created! Exiting...")
        print("‚ö† No split files were created! Exiting...")

    return logs  # ‚úÖ Return messages for Streamlit UI
